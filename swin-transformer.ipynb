{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1165040,"sourceType":"datasetVersion","datasetId":660021}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import model_selection, metrics\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer, Multiply,GlobalAveragePooling1D,MultiHeadAttention,Embedding,Lambda,Dense,Flatten,Conv2D,Dropout, Conv2DTranspose, MaxPooling2D, Input, Activation, Concatenate, UpSampling2D, Resizing,Reshape,Add,LayerNormalization,BatchNormalization\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam,SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\nfrom tensorflow.keras.saving import register_keras_serializable\nimport cv2\nfrom PIL import Image\nfrom tensorflow import keras\nimport pickle\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:51:59.022157Z","iopub.execute_input":"2025-01-15T09:51:59.022478Z","iopub.status.idle":"2025-01-15T09:52:13.119766Z","shell.execute_reply.started":"2025-01-15T09:51:59.022454Z","shell.execute_reply":"2025-01-15T09:52:13.118893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = '/kaggle/input/satellite-images-of-water-bodies/Water Bodies Dataset'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:13.120983Z","iopub.execute_input":"2025-01-15T09:52:13.121687Z","iopub.status.idle":"2025-01-15T09:52:13.125703Z","shell.execute_reply.started":"2025-01-15T09:52:13.121626Z","shell.execute_reply":"2025-01-15T09:52:13.124755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = tf.keras.utils.image_dataset_from_directory(directory = path, image_size = (128, 128), batch_size = 6000, shuffle = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:13.127193Z","iopub.execute_input":"2025-01-15T09:52:13.127505Z","iopub.status.idle":"2025-01-15T09:52:19.874800Z","shell.execute_reply.started":"2025-01-15T09:52:13.127468Z","shell.execute_reply":"2025-01-15T09:52:19.873938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, masks in data:\n    X = images.numpy().astype(\"uint8\")\n    y = masks.numpy().astype(\"uint8\")\n\nprint(X.shape, y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:19.876113Z","iopub.execute_input":"2025-01-15T09:52:19.876396Z","iopub.status.idle":"2025-01-15T09:52:32.792373Z","shell.execute_reply.started":"2025-01-15T09:52:19.876372Z","shell.execute_reply":"2025-01-15T09:52:32.791511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images = X[y == 0]\nmasks = X[y == 1]\n\nprint(images.shape, masks.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:32.793497Z","iopub.execute_input":"2025-01-15T09:52:32.793881Z","iopub.status.idle":"2025-01-15T09:52:32.999419Z","shell.execute_reply.started":"2025-01-15T09:52:32.793844Z","shell.execute_reply":"2025-01-15T09:52:32.998478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = model_selection.train_test_split(images, masks, test_size = 0.2, random_state = 3)\n\nprint(X_train.shape, X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:33.000422Z","iopub.execute_input":"2025-01-15T09:52:33.000708Z","iopub.status.idle":"2025-01-15T09:52:33.097806Z","shell.execute_reply.started":"2025-01-15T09:52:33.000676Z","shell.execute_reply":"2025-01-15T09:52:33.096769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert masks to single channel (binary)\ny_train = (y_train[..., 0] > 0).astype(\"uint8\")  # Assuming the first channel represents the mask\ny_test = (y_test[..., 0] > 0).astype(\"uint8\")\nprint(y_train.shape, y_test.shape)\n# Reshape your target arrays to match the model's output shape\ny_train = y_train.reshape((-1, 128, 128, 1))\ny_test = y_test.reshape((-1, 128, 128, 1))\n\nprint(y_train.shape, y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:33.098741Z","iopub.execute_input":"2025-01-15T09:52:33.099070Z","iopub.status.idle":"2025-01-15T09:52:33.178631Z","shell.execute_reply.started":"2025-01-15T09:52:33.099044Z","shell.execute_reply":"2025-01-15T09:52:33.177686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters\nconfig = {}\n\nconfig[\"image_size\"] = 128\nconfig[\"num_channels\"] = 3\nconfig[\"patch_size\"] = 16\nconfig[\"num_patches\"] = (config[\"image_size\"]**2) // (config[\"patch_size\"]**2) # 128x128/16x16 = 64\nconfig[\"flat_patches_shape\"] = (config[\"num_patches\"], config[\"patch_size\"],config[\"patch_size\"],config[\"num_channels\"]) # 113 x 113 x 113 x 3\nconfig[\"input_shape\"] = (config[\"num_patches\"], config[\"patch_size\"]*config[\"patch_size\"]*config[\"num_channels\"]) # 113 patches, 768 elements each\nconfig[\"classes\"] = [\"water\",\"no water\" ]\nconfig[\"window_size\"] = 8\nconfig[\"num_stages\"] = 4\n\nconfig[\"num_layers\"] = 12\nconfig[\"hidden_dim\"] = 64\nconfig[\"mlp_dim\"] = 128\nconfig[\"num_heads\"] = 8\nconfig[\"dropout_rate\"] = 0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T11:29:19.603459Z","iopub.execute_input":"2025-01-15T11:29:19.603901Z","iopub.status.idle":"2025-01-15T11:29:19.611440Z","shell.execute_reply.started":"2025-01-15T11:29:19.603866Z","shell.execute_reply":"2025-01-15T11:29:19.610476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_patches(images, patch_size):\n    # first get the number of patches in each dimension\n    #print(f\"Batch Size: {images.shape[0]}\")\n    #print(f\"Image Size: {images.shape[1]}\")\n    #print(f\"Number of Channels: {images.shape[3]}\")\n    #print(f\"Patch Size: {patch_size}\")\n    H_patches = images.shape[1] // patch_size\n    W_patches = images.shape[2] // patch_size\n    #print(f\"Patches in each dimension: {num_patches_per_dim}\")\n\n    # Reshape images to (batch_size, H_patches, patch_size, W_patches, patch_size, num_channels)\n    patches = images.reshape(\n        images.shape[0],\n        H_patches,\n        patch_size,\n        W_patches,\n        patch_size,\n        images.shape[3]\n    )\n    #print(f\"Reahped Image: {patches.shape} and length is {len(patches.shape)}\")\n    # Transpose to get patches: (batch_size, H_patches, W_patches, patch_size^2 * channels)\n    patches = patches.transpose(0, 1, 2, 3, 4, 5).reshape(\n        images.shape[0], H_patches, W_patches, patch_size * patch_size * images.shape[3]\n    )\n    #print(f\"Final Patches {patches.shape}\")\n\n    return patches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:33.190291Z","iopub.execute_input":"2025-01-15T09:52:33.190566Z","iopub.status.idle":"2025-01-15T09:52:33.207774Z","shell.execute_reply.started":"2025-01-15T09:52:33.190542Z","shell.execute_reply":"2025-01-15T09:52:33.206547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_patches = create_patches(X_train, config[\"patch_size\"])\nX_test_patches = create_patches(X_test, config[\"patch_size\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:56:59.051350Z","iopub.execute_input":"2025-01-15T09:56:59.051803Z","iopub.status.idle":"2025-01-15T09:56:59.056607Z","shell.execute_reply.started":"2025-01-15T09:56:59.051767Z","shell.execute_reply":"2025-01-15T09:56:59.055504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Train Patches: {X_train_patches.shape} \\nTest Patches: {X_test_patches.shape}\")\nprint(f\"Image size: {config['image_size']} X {config['image_size']}\")\nprint(f\"Patch Size: {config['patch_size']} X {config['patch_size']}\")\nprint(f\"Patch per Image: {X_train_patches.shape[1]} \\nPatch Dimension: {X_train_patches.shape[-1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:56:59.952921Z","iopub.execute_input":"2025-01-15T09:56:59.953259Z","iopub.status.idle":"2025-01-15T09:56:59.960032Z","shell.execute_reply.started":"2025-01-15T09:56:59.953234Z","shell.execute_reply":"2025-01-15T09:56:59.959106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_image = X_train[0]\nsample_patches = create_patches(np.expand_dims(sample_image, axis=0), config[\"patch_size\"])[0]\nprint(f\"Patch Shape{sample_patches.shape}\")\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(sample_image.astype(\"uint8\"))\nplt.title(\"Original Image\")\nplt.axis(\"off\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:33.252146Z","iopub.execute_input":"2025-01-15T09:52:33.252530Z","iopub.status.idle":"2025-01-15T09:52:33.503095Z","shell.execute_reply.started":"2025-01-15T09:52:33.252494Z","shell.execute_reply":"2025-01-15T09:52:33.501996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_patches = sample_patches.shape[0] * sample_patches.shape[1]\nprint(num_patches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:57:04.017619Z","iopub.execute_input":"2025-01-15T09:57:04.018024Z","iopub.status.idle":"2025-01-15T09:57:04.023456Z","shell.execute_reply.started":"2025-01-15T09:57:04.017996Z","shell.execute_reply":"2025-01-15T09:57:04.022290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n = int(np.sqrt(num_patches)) # n should be square root of number of patches\nprint(f\"Total Patch of a image: {num_patches} \\nNumber of patches in 1 dimension: {n}\")\n\nplt.figure(figsize = (4,4))\nsample_patch = sample_patches.reshape(num_patches,sample_patches.shape[2])\nprint(sample_patch.shape)\n\n# Iterate through the patches, not elements of a patch\nfor i, patch in enumerate(sample_patch):\n    ax = plt.subplot(n, n, i + 1)\n    # Reshape the entire patch\n    patch_image = patch.reshape(config['patch_size'], config['patch_size'], sample_image.shape[-1])\n    plt.imshow(patch_image.astype('uint8'))\n    plt.axis(\"off\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T13:29:33.018472Z","iopub.execute_input":"2025-01-14T13:29:33.018807Z","iopub.status.idle":"2025-01-14T13:29:35.230639Z","shell.execute_reply.started":"2025-01-14T13:29:33.018780Z","shell.execute_reply":"2025-01-14T13:29:35.229508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def linear_embedding(inputs, cf):\n    embdedding = Dense(cf['hidden_dim'])(inputs)\n    print(embdedding.shape)\n    \n    return embdedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:23:11.723894Z","iopub.execute_input":"2025-01-15T10:23:11.724319Z","iopub.status.idle":"2025-01-15T10:23:11.729590Z","shell.execute_reply.started":"2025-01-15T10:23:11.724289Z","shell.execute_reply":"2025-01-15T10:23:11.728298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_embedded = linear_embedding(X_train_patches, config)\nX_test_embedded = linear_embedding(X_test_patches, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:23:14.065594Z","iopub.execute_input":"2025-01-15T10:23:14.066074Z","iopub.status.idle":"2025-01-15T10:23:15.478070Z","shell.execute_reply.started":"2025-01-15T10:23:14.066042Z","shell.execute_reply":"2025-01-15T10:23:15.477148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def window_partition(x, window_size):\n    B, H, W, C = x.shape\n    x = tf.reshape(x, [B, H // window_size, window_size, W // window_size, window_size, C])\n    windows = tf.reshape(x, [-1, window_size, window_size, C])\n    \n    return windows","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:34.706598Z","iopub.execute_input":"2025-01-15T09:52:34.706987Z","iopub.status.idle":"2025-01-15T09:52:34.712385Z","shell.execute_reply.started":"2025-01-15T09:52:34.706950Z","shell.execute_reply":"2025-01-15T09:52:34.711430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def shifted_window_partition(x, window_size):\n    \"\"\"Shifts and partitions the input into windows.\"\"\"\n    # Shift the input tensor by half the window size\n    shift_amount = window_size // 2\n    shifted_x = tf.roll(x, shift=[-shift_amount, -shift_amount], axis=[1, 2])\n    \n    # Partition into windows (similar to window_partition function)\n    B, H, W, C = shifted_x.shape\n    x = tf.reshape(shifted_x, [B, H // window_size, window_size, W // window_size, window_size, C])\n    windows = tf.reshape(x, [-1, window_size, window_size, C])\n    \n    return windows","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:34.713316Z","iopub.execute_input":"2025-01-15T09:52:34.713587Z","iopub.status.idle":"2025-01-15T09:52:34.730386Z","shell.execute_reply.started":"2025-01-15T09:52:34.713551Z","shell.execute_reply":"2025-01-15T09:52:34.729247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def merge_windows(windows, window_size, original_shape):\n    \"\"\"Merge windows back to original image shape after attention.\"\"\"\n    B, H, W, C = original_shape\n    x = tf.reshape(windows, [B, H // window_size, W // window_size, window_size, window_size, C])\n    x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n    x = tf.reshape(x, [B, H, W, C])\n    \n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:52:34.731520Z","iopub.execute_input":"2025-01-15T09:52:34.731918Z","iopub.status.idle":"2025-01-15T09:52:34.740324Z","shell.execute_reply.started":"2025-01-15T09:52:34.731890Z","shell.execute_reply":"2025-01-15T09:52:34.739474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_attention_mask(window_size):\n    # Initialize a square mask of size (window_size^2, window_size^2)\n    mask = tf.zeros((window_size**2, window_size**2), dtype=tf.float32)\n    \n    # Define the indices for masking (example: upper triangle)\n    indices = []\n    for i in range(window_size):\n        for j in range(window_size // 2, window_size):\n            indices.append([i * window_size + j, j * window_size + i])  # Adjust indices\n\n    indices = tf.convert_to_tensor(indices, dtype=tf.int32)\n\n    # Define the update values for the mask\n    updates = tf.fill([len(indices)], float('-inf'))  # Match number of updates with indices\n\n    # Apply scatter update\n    mask = tf.tensor_scatter_nd_update(mask, indices, updates)\n\n    return mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:59:42.742405Z","iopub.execute_input":"2025-01-15T09:59:42.742877Z","iopub.status.idle":"2025-01-15T09:59:42.750492Z","shell.execute_reply.started":"2025-01-15T09:59:42.742845Z","shell.execute_reply":"2025-01-15T09:59:42.748905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mlp(x, cf):\n    x = Dense(cf[\"mlp_dim\"], activation = \"gelu\")(x)\n    x = Dropout(cf[\"dropout_rate\"])(x)\n    #x = LayerNormalization()(x)\n    x = Dense(cf[\"hidden_dim\"])(x)\n    x = Dropout(cf[\"dropout_rate\"])(x)\n    \n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T09:58:34.781059Z","iopub.execute_input":"2025-01-15T09:58:34.781405Z","iopub.status.idle":"2025-01-15T09:58:34.786432Z","shell.execute_reply.started":"2025-01-15T09:58:34.781378Z","shell.execute_reply":"2025-01-15T09:58:34.785284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def patch_merging(x, cf):\n    H, W, C = x.shape[1], x.shape[2], x.shape[3]\n    x = tf.reshape(x, [-1, H // 2, 2, W // 2, 2, C])\n    x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n    x = tf.reshape(x, [-1, H // 2, W // 2, 4 * C])\n    x = Dense(cf['hidden_dim'] * 2)(x)\n    x = LayerNormalization()(x)\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:20:05.760067Z","iopub.execute_input":"2025-01-15T10:20:05.760802Z","iopub.status.idle":"2025-01-15T10:20:05.769152Z","shell.execute_reply.started":"2025-01-15T10:20:05.760759Z","shell.execute_reply":"2025-01-15T10:20:05.767759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SwinEncoderBlock(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, window_size, mask, cf):\n        super(SwinEncoderBlock, self).__init__()\n        self.layer_norm = LayerNormalization()\n        self.dropout = Dropout(0.1)\n        self.window_size = window_size\n        self.mask = mask\n        self.hidden_dim = cf[\"hidden_dim\"]\n\n    def call(self, x, cf):\n        # Window Self-Attention (WSA)\n        res1 = self.dropout(self.layer_norm(x) + x)\n        windows = window_partition(res1, self.window_size)  # Partition into windows\n        attention_output = multihead_attention(\n            windows, self.num_heads, self.hidden_dim, self.window_size\n        )\n\n        # Shifted Window Self-Attention (SWSA)\n        res2 = self.dropout(self.layer_norm(attention_output) + attention_output)\n        shifted_windows = shifted_window_partition(res2, self.window_size)  # Shift windows\n        attention_output2 = multihead_attention(\n            shifted_windows, self.num_heads, self.hidden_dim, self.window_size\n        )\n\n        # Apply MLP after shifted window self-attention\n        x = self.layer_norm(attention_output2)\n        x = mlp(x, cf)\n        return self.dropout(x + res2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T11:10:51.049727Z","iopub.execute_input":"2025-01-15T11:10:51.050733Z","iopub.status.idle":"2025-01-15T11:10:51.062943Z","shell.execute_reply.started":"2025-01-15T11:10:51.050670Z","shell.execute_reply":"2025-01-15T11:10:51.061393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AlternatingEncoderBlock(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, window_size, cf = None):\n        super(AlternatingEncoderBlock, self).__init__()\n        self.WSA = SwinEncoderBlock(\n            embed_dim=embed_dim, \n            num_heads=num_heads, \n            window_size=window_size, \n            mask=False,\n            cf = cf\n        )\n        self.SWSA = SwinEncoderBlock(\n            embed_dim=embed_dim, \n            num_heads=num_heads, \n            window_size=window_size, \n            mask=True,\n            cf = cf\n        )\n\n    def call(self, x):\n        x = self.WSA(x) # Apply Window Self-Attention first\n        return self.SWSA(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T11:33:12.407126Z","iopub.execute_input":"2025-01-15T11:33:12.407728Z","iopub.status.idle":"2025-01-15T11:33:12.415920Z","shell.execute_reply.started":"2025-01-15T11:33:12.407677Z","shell.execute_reply":"2025-01-15T11:33:12.414732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SwinTransformer(tf.keras.Model):\n    def __init__(self, cf):\n        super(SwinTransformer, self).__init__()\n        self.Embedding = linear_embedding  # You can define your custom embedding layer\n        self.PatchMerge1 = patch_merging\n        self.PatchMerge2 = patch_merging\n        self.PatchMerge3 = patch_merging\n\n        self.Stage1 = AlternatingEncoderBlock(96, cf['num_heads'], cf['window_size'], cf)\n        self.Stage2 = AlternatingEncoderBlock(192, cf['num_heads'], cf['window_size'], cf)\n        self.Stage3_1 = AlternatingEncoderBlock(384, cf['num_heads'], cf['window_size'], cf)\n        self.Stage3_2 = AlternatingEncoderBlock(384, cf['num_heads'], cf['window_size'], cf)\n        self.Stage3_3 = AlternatingEncoderBlock(384, cf['num_heads'], cf['window_size'], cf)\n        self.Stage4 = AlternatingEncoderBlock(768, cf['num_heads'], cf['window_size'], cf)\n\n    def call(self, x, cf):\n        x = self.Embedding(x, cf)\n        x = self.PatchMerge1(self.Stage1(x, cf))\n        x = self.PatchMerge2(self.Stage2(x, cf))\n        x = self.Stage3_1(x, cf)\n        x = self.Stage3_2(x, cf)\n        x = self.Stage3_3(x, cf)\n        x = self.PatchMerge3(x, cf)\n        x = self.Stage4(x, cf)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T11:33:22.423396Z","iopub.execute_input":"2025-01-15T11:33:22.423877Z","iopub.status.idle":"2025-01-15T11:33:22.432960Z","shell.execute_reply.started":"2025-01-15T11:33:22.423836Z","shell.execute_reply":"2025-01-15T11:33:22.431530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(128, 128, 3))  # Example input shape\nswin_transformer_model = SwinTransformer(config)\n\n# Pass the input tensor through the model\nx = swin_transformer_model(inputs, config)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T11:34:40.951259Z","iopub.execute_input":"2025-01-15T11:34:40.951702Z","iopub.status.idle":"2025-01-15T11:34:41.036356Z","shell.execute_reply.started":"2025-01-15T11:34:40.951669Z","shell.execute_reply":"2025-01-15T11:34:41.034756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transformer_encoder(x, cf):\n    skip1 = x\n    x = LayerNormalization()(x)\n    x = MultiHeadAttention(num_heads = cf[\"num_heads\"], key_dim = cf[\"hidden_dim\"])(x,x)\n    x = Add()([x, skip1])\n    \n    skip2 = x\n    x = LayerNormalization()(x)\n    x = mlp(x,cf)\n    x = Add()([x, skip2])\n\n    skip3 = x\n    x = LayerNormalization()(x)\n    x = shifted_window_partition(x, cf[\"window_size\"])\n    attention_mask = create_attention_mask(cf[\"window_size\"])\n    x = tf.reshape(x, (x.shape[0], -1, x.shape[-1]))\n    x = MultiHeadAttention(num_heads = cf[\"num_heads\"], key_dim = cf[\"hidden_dim\"])(x,x, attention_mask=attention_mask)\n    x = merge_windows(x, cf[\"window_size\"], skip1.shape)\n    x = Add()([x, skip3])\n\n    skip4 = x\n    x = LayerNormalization()(x)\n    x = mlp(x,cf)\n    x = Add()([x, skip4])\n    \n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:03:22.264305Z","iopub.execute_input":"2025-01-15T10:03:22.264750Z","iopub.status.idle":"2025-01-15T10:03:22.272357Z","shell.execute_reply.started":"2025-01-15T10:03:22.264713Z","shell.execute_reply":"2025-01-15T10:03:22.271014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = window_partition(X_train_embedded, config[\"window_size\"])\nx = transformer_encoder(x, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:03:23.805775Z","iopub.execute_input":"2025-01-15T10:03:23.806186Z","iopub.status.idle":"2025-01-15T10:03:34.796924Z","shell.execute_reply.started":"2025-01-15T10:03:23.806157Z","shell.execute_reply":"2025-01-15T10:03:34.795949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"outputs = swin_transformer(X_train, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T08:16:46.111242Z","iopub.execute_input":"2025-01-15T08:16:46.111597Z","iopub.status.idle":"2025-01-15T08:17:12.036241Z","shell.execute_reply.started":"2025-01-15T08:16:46.111568Z","shell.execute_reply":"2025-01-15T08:17:12.034907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(outputs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T08:14:54.904191Z","iopub.execute_input":"2025-01-15T08:14:54.904633Z","iopub.status.idle":"2025-01-15T08:14:54.910866Z","shell.execute_reply.started":"2025-01-15T08:14:54.904600Z","shell.execute_reply":"2025-01-15T08:14:54.909595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Model(inputs= Input(shape = (128, 128, 3)), outputs=outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T08:14:22.404114Z","iopub.execute_input":"2025-01-15T08:14:22.404524Z","iopub.status.idle":"2025-01-15T08:14:22.440561Z","shell.execute_reply.started":"2025-01-15T08:14:22.404490Z","shell.execute_reply":"2025-01-15T08:14:22.438748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def window_reverse(windows, window_size, H, W):\n    B = windows.shape[0] // (H // window_size * W // window_size)\n    \n    # Check for valid shapes\n    assert (H % window_size == 0) and (W % window_size == 0), \"H and W must be divisible by window_size\"\n    \n    x = tf.reshape(windows, [B, H // window_size, W // window_size, window_size, window_size, -1])\n    x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])  # Transpose back to original spatial positions\n    x = tf.reshape(x, [B, H, W, -1])\n    return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T12:35:34.561586Z","iopub.execute_input":"2025-01-14T12:35:34.561926Z","iopub.status.idle":"2025-01-14T12:35:34.567970Z","shell.execute_reply.started":"2025-01-14T12:35:34.561898Z","shell.execute_reply":"2025-01-14T12:35:34.566818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def swin_transformer(x, cf):\n    x = window_partition(x, 4)\n    print(x.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T12:10:57.617248Z","iopub.execute_input":"2025-01-14T12:10:57.617618Z","iopub.status.idle":"2025-01-14T12:10:57.621827Z","shell.execute_reply.started":"2025-01-14T12:10:57.617588Z","shell.execute_reply":"2025-01-14T12:10:57.620654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"swin_transformer(X_train_embedded, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T11:57:31.161610Z","iopub.execute_input":"2025-01-14T11:57:31.161988Z","iopub.status.idle":"2025-01-14T11:57:32.333335Z","shell.execute_reply.started":"2025-01-14T11:57:31.161918Z","shell.execute_reply":"2025-01-14T11:57:32.332381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}